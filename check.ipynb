{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/lbw1125/Library/Python/3.11/lib/python/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/lbw1125/Library/Python/3.11/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Python pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the temporary inability to implement certain code in SQL, such as WordVec, I have commented out these sections to obtain data from other operations. I have stored intermediate outputs as corresponding CSV files, and the train and test data used for model training after various operations have been saved as TXT files. This facilitates subsequent checks to ensure consistency between the data obtained from SQL operations and these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer(transformers=[('numerical_features', StandardScaler(),\n",
      "                                 ['weight']),\n",
      "                                ('categorical_features',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['smokes'])])\n",
      "Pipeline(steps=[('features',\n",
      "                 ColumnTransformer(transformers=[('numerical_features',\n",
      "                                                  StandardScaler(),\n",
      "                                                  ['weight']),\n",
      "                                                 ('categorical_features',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['smokes'])]))])\n"
     ]
    }
   ],
   "source": [
    "# pylint: disable-all\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy \n",
    "import pandas as pd\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#from example_pipelines.healthcare.healthcare_utils import MyW2VTransformer, MyKerasClassifier\n",
    "\n",
    "# Disable tensorflow API and optimization warnings for a readable output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 1234\n",
    "tensorflow.random.set_seed(seed)\n",
    "numpy.seed = seed\n",
    "\n",
    "\n",
    "def combine(patients, patient_histories, consent_required):\n",
    "    if consent_required:\n",
    "        patients = patients[patients['gave_consent'] == True]\n",
    "    with_history = patients.merge(patient_histories, on=\"ssn\")\n",
    "    return with_history\n",
    "\n",
    "\n",
    "def create_neural_net(input_dim):\n",
    "    # Model definition\n",
    "    nn = Sequential([\n",
    "        Dense(8, activation='relu', input_dim=input_dim), Dropout(0.3),\n",
    "        Dense(4, activation='relu'),\n",
    "        Dense(2, activation='softmax')])\n",
    "    nn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "    return nn\n",
    "\n",
    "\n",
    "def featurization():\n",
    "    # Featurization\n",
    "    encode = ColumnTransformer(transformers=[\n",
    "        ('numerical_features', StandardScaler(), ['weight']),\n",
    "        ('categorical_features', OneHotEncoder(handle_unknown='ignore'), ['smokes'])])\n",
    "        #('textual_features', MyW2VTransformer(min_count=1, size=5), ['notes'])])\n",
    "    print(encode)\n",
    "    return encode\n",
    "\n",
    "\n",
    "def execute_pipeline():\n",
    "    # Relational preprocessing\n",
    "    patients = pd.read_csv(\"patients.csv\")\n",
    "    histories = pd.read_csv(\"histories.csv\")\n",
    "    test_histories = pd.read_csv(\"test_histories.csv\")\n",
    "    \n",
    "    histories = histories[histories['hospital'].isin([\"AL\", \"AK\", \"AR\"])]\n",
    "    # Export the DataFrame to a CSV file for subsequent inspection and comparison. Additionally, for ease of comparison, sort the DataFrame by SSN. The following operations are similar.\n",
    "    histories_sorted = histories.sort_values('ssn')\n",
    "    histories_sorted.to_csv('histories_pipeline.csv', index=False)\n",
    "\n",
    "    train = combine(patients, histories, consent_required=True)\n",
    "    train_sorted = train.sort_values('ssn')\n",
    "    train_sorted.to_csv('train_pipeline_initial.csv', index=False)\n",
    "\n",
    "    test = combine(patients, test_histories, consent_required=True)\n",
    "    test_sorted = test.sort_values('ssn')\n",
    "    test_sorted.to_csv('test_pipeline_initial.csv', index=False)\n",
    "\n",
    "    encode_and_learn = Pipeline([\n",
    "        ('features', featurization())])\n",
    "        #('learner', MyKerasClassifier(create_neural_net, epochs=5, verbose=0))])\n",
    "    model = encode_and_learn.fit(train, train['has_complication'])\n",
    "    print(model)\n",
    "    #pred = model.predict(test)\n",
    "    #return accuracy_score(test['has_complication'], pred)\n",
    "    \n",
    "    # Store the final train and test datasets for convenient comparison at the end.\n",
    "    train_transformed = encode_and_learn.transform(train)\n",
    "    test_transformed = encode_and_learn.transform(test)\n",
    "    \n",
    "    numpy.savetxt('train_transformed.txt', train_transformed)\n",
    "    numpy.savetxt('test_transformed.txt', test_transformed)\n",
    "\n",
    "    return 1\n",
    "\n",
    "\n",
    "score = execute_pipeline()\n",
    "#print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation in DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckdb in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.9.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext sql\n",
    "conn = duckdb.connect()\n",
    "%sql conn --alias duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>notes</th>\n",
       "            <th>has_complication</th>\n",
       "            <th>ssn</th>\n",
       "            <th>hospital</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>819-66-5146</td>\n",
       "            <td>AK</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>140-45-9448</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>high risk</td>\n",
       "            <td>False</td>\n",
       "            <td>643-13-0728</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>661-10-1912</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>702-18-9881</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>168-69-3664</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>078-52-8543</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>567-03-8647</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>296-18-9628</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>813-71-5848</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<span style=\"font-style:italic;text-align:center;\">Truncated to <a href=\"https://jupysql.ploomber.io/en/latest/api/configuration.html#displaylimit\">displaylimit</a> of 10.</span>"
      ],
      "text/plain": [
       "+-------------+------------------+-------------+----------+\n",
       "|    notes    | has_complication |     ssn     | hospital |\n",
       "+-------------+------------------+-------------+----------+\n",
       "| normal risk |      False       | 819-66-5146 |    AK    |\n",
       "| normal risk |      False       | 140-45-9448 |    AR    |\n",
       "|  high risk  |      False       | 643-13-0728 |    AL    |\n",
       "| normal risk |      False       | 661-10-1912 |    AZ    |\n",
       "| normal risk |      False       | 702-18-9881 |    AL    |\n",
       "| normal risk |       True       | 168-69-3664 |    AR    |\n",
       "| normal risk |       True       | 078-52-8543 |    AR    |\n",
       "| normal risk |       True       | 567-03-8647 |    AZ    |\n",
       "| normal risk |      False       | 296-18-9628 |    AL    |\n",
       "| normal risk |      False       | 813-71-5848 |    AZ    |\n",
       "+-------------+------------------+-------------+----------+\n",
       "Truncated to displaylimit of 10."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE histories AS SELECT * FROM read_csv_auto('histories.csv');\n",
    "SELECT * FROM histories;\n",
    "\n",
    "CREATE TABLE patients AS SELECT * FROM read_csv_auto('patients.csv');\n",
    "SELECT * FROM patients;\n",
    "\n",
    "CREATE TABLE test_histories AS SELECT * FROM read_csv_auto('test_histories.csv');\n",
    "SELECT * FROM test_histories;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>notes</th>\n",
       "            <th>has_complication</th>\n",
       "            <th>ssn</th>\n",
       "            <th>hospital</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>844-25-3185</td>\n",
       "            <td>AK</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>704-22-1415</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>291-52-4957</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>554-60-6241</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>371-22-8266</td>\n",
       "            <td>AK</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>761-31-5342</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>high risk</td>\n",
       "            <td>False</td>\n",
       "            <td>423-64-3297</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>763-29-0394</td>\n",
       "            <td>AK</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>365-08-4223</td>\n",
       "            <td>AK</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>high risk</td>\n",
       "            <td>True</td>\n",
       "            <td>150-03-7624</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<span style=\"font-style:italic;text-align:center;\">Truncated to <a href=\"https://jupysql.ploomber.io/en/latest/api/configuration.html#displaylimit\">displaylimit</a> of 10.</span>"
      ],
      "text/plain": [
       "+-------------+------------------+-------------+----------+\n",
       "|    notes    | has_complication |     ssn     | hospital |\n",
       "+-------------+------------------+-------------+----------+\n",
       "| normal risk |      False       | 844-25-3185 |    AK    |\n",
       "| normal risk |       True       | 704-22-1415 |    AR    |\n",
       "| normal risk |      False       | 291-52-4957 |    AL    |\n",
       "| normal risk |      False       | 554-60-6241 |    AL    |\n",
       "| normal risk |      False       | 371-22-8266 |    AK    |\n",
       "| normal risk |       True       | 761-31-5342 |    AR    |\n",
       "|  high risk  |      False       | 423-64-3297 |    AZ    |\n",
       "| normal risk |      False       | 763-29-0394 |    AK    |\n",
       "| normal risk |      False       | 365-08-4223 |    AK    |\n",
       "|  high risk  |       True       | 150-03-7624 |    AZ    |\n",
       "+-------------+------------------+-------------+----------+\n",
       "Truncated to displaylimit of 10."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM histories;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>smokes</th>\n",
       "            <th>weight</th>\n",
       "            <th>gave_consent</th>\n",
       "            <th>ssn</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>no</td>\n",
       "            <td>57.98341830412999</td>\n",
       "            <td>True</td>\n",
       "            <td>844-25-3185</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>no</td>\n",
       "            <td>62.741663157827546</td>\n",
       "            <td>True</td>\n",
       "            <td>704-22-1415</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>no</td>\n",
       "            <td>81.73846816241817</td>\n",
       "            <td>True</td>\n",
       "            <td>291-52-4957</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>no</td>\n",
       "            <td>58.33552143345234</td>\n",
       "            <td>True</td>\n",
       "            <td>554-60-6241</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>no</td>\n",
       "            <td>77.18224566942787</td>\n",
       "            <td>False</td>\n",
       "            <td>371-22-8266</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>yes</td>\n",
       "            <td>71.09854327546942</td>\n",
       "            <td>True</td>\n",
       "            <td>761-31-5342</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>yes</td>\n",
       "            <td>81.13481270935448</td>\n",
       "            <td>True</td>\n",
       "            <td>423-64-3297</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>no</td>\n",
       "            <td>74.23670445374523</td>\n",
       "            <td>True</td>\n",
       "            <td>763-29-0394</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>no</td>\n",
       "            <td>84.64247606449092</td>\n",
       "            <td>True</td>\n",
       "            <td>365-08-4223</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>yes</td>\n",
       "            <td>61.95273301921088</td>\n",
       "            <td>True</td>\n",
       "            <td>150-03-7624</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<span style=\"font-style:italic;text-align:center;\">Truncated to <a href=\"https://jupysql.ploomber.io/en/latest/api/configuration.html#displaylimit\">displaylimit</a> of 10.</span>"
      ],
      "text/plain": [
       "+--------+--------------------+--------------+-------------+\n",
       "| smokes |       weight       | gave_consent |     ssn     |\n",
       "+--------+--------------------+--------------+-------------+\n",
       "|   no   | 57.98341830412999  |     True     | 844-25-3185 |\n",
       "|   no   | 62.741663157827546 |     True     | 704-22-1415 |\n",
       "|   no   | 81.73846816241817  |     True     | 291-52-4957 |\n",
       "|   no   | 58.33552143345234  |     True     | 554-60-6241 |\n",
       "|   no   | 77.18224566942787  |    False     | 371-22-8266 |\n",
       "|  yes   | 71.09854327546942  |     True     | 761-31-5342 |\n",
       "|  yes   | 81.13481270935448  |     True     | 423-64-3297 |\n",
       "|   no   | 74.23670445374523  |     True     | 763-29-0394 |\n",
       "|   no   | 84.64247606449092  |     True     | 365-08-4223 |\n",
       "|  yes   | 61.95273301921088  |     True     | 150-03-7624 |\n",
       "+--------+--------------------+--------------+-------------+\n",
       "Truncated to displaylimit of 10."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM patients;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>notes</th>\n",
       "            <th>has_complication</th>\n",
       "            <th>ssn</th>\n",
       "            <th>hospital</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>819-66-5146</td>\n",
       "            <td>AK</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>140-45-9448</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>high risk</td>\n",
       "            <td>False</td>\n",
       "            <td>643-13-0728</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>661-10-1912</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>702-18-9881</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>168-69-3664</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>078-52-8543</td>\n",
       "            <td>AR</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>True</td>\n",
       "            <td>567-03-8647</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>296-18-9628</td>\n",
       "            <td>AL</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>normal risk</td>\n",
       "            <td>False</td>\n",
       "            <td>813-71-5848</td>\n",
       "            <td>AZ</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<span style=\"font-style:italic;text-align:center;\">Truncated to <a href=\"https://jupysql.ploomber.io/en/latest/api/configuration.html#displaylimit\">displaylimit</a> of 10.</span>"
      ],
      "text/plain": [
       "+-------------+------------------+-------------+----------+\n",
       "|    notes    | has_complication |     ssn     | hospital |\n",
       "+-------------+------------------+-------------+----------+\n",
       "| normal risk |      False       | 819-66-5146 |    AK    |\n",
       "| normal risk |      False       | 140-45-9448 |    AR    |\n",
       "|  high risk  |      False       | 643-13-0728 |    AL    |\n",
       "| normal risk |      False       | 661-10-1912 |    AZ    |\n",
       "| normal risk |      False       | 702-18-9881 |    AL    |\n",
       "| normal risk |       True       | 168-69-3664 |    AR    |\n",
       "| normal risk |       True       | 078-52-8543 |    AR    |\n",
       "| normal risk |       True       | 567-03-8647 |    AZ    |\n",
       "| normal risk |      False       | 296-18-9628 |    AL    |\n",
       "| normal risk |      False       | 813-71-5848 |    AZ    |\n",
       "+-------------+------------------+-------------+----------+\n",
       "Truncated to displaylimit of 10."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM test_histories;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example in the paper, I first transformed the Python code for each node in the DAG using CTE. However, here, for the convenience of comparing the results obtained from SQL with those obtained by running Python code, I have converted it into a View."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>has_complication</th>\n",
       "            <th>patient_rowid</th>\n",
       "            <th>test_rowid</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10001</td>\n",
       "            <td>1</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10002</td>\n",
       "            <td>2</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10004</td>\n",
       "            <td>4</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>True</td>\n",
       "            <td>10005</td>\n",
       "            <td>5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>True</td>\n",
       "            <td>10006</td>\n",
       "            <td>6</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>True</td>\n",
       "            <td>10007</td>\n",
       "            <td>7</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10008</td>\n",
       "            <td>8</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10009</td>\n",
       "            <td>9</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10011</td>\n",
       "            <td>11</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>False</td>\n",
       "            <td>10013</td>\n",
       "            <td>13</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<span style=\"font-style:italic;text-align:center;\">Truncated to <a href=\"https://jupysql.ploomber.io/en/latest/api/configuration.html#displaylimit\">displaylimit</a> of 10.</span>"
      ],
      "text/plain": [
       "+------------------+---------------+------------+\n",
       "| has_complication | patient_rowid | test_rowid |\n",
       "+------------------+---------------+------------+\n",
       "|      False       |     10001     |     1      |\n",
       "|      False       |     10002     |     2      |\n",
       "|      False       |     10004     |     4      |\n",
       "|       True       |     10005     |     5      |\n",
       "|       True       |     10006     |     6      |\n",
       "|       True       |     10007     |     7      |\n",
       "|      False       |     10008     |     8      |\n",
       "|      False       |     10009     |     9      |\n",
       "|      False       |     10011     |     11     |\n",
       "|      False       |     10013     |     13     |\n",
       "+------------------+---------------+------------+\n",
       "Truncated to displaylimit of 10."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "-- CTE: Original History\n",
    "WITH orig_history AS (\n",
    "    SELECT rowid AS history_rowid, * FROM histories\n",
    "),\n",
    "\n",
    "-- CTE: Original Test\n",
    "orig_test AS (\n",
    "    SELECT rowid AS test_rowid, * FROM test_histories\n",
    "),\n",
    "\n",
    "-- CTE: Original Patient\n",
    "orig_patient AS (\n",
    "    SELECT rowid AS patient_rowid, * FROM patients\n",
    "),\n",
    "\n",
    "-- CTE: Block 3\n",
    "block_3 AS (\n",
    "    SELECT hospital, history_rowid FROM orig_history\n",
    "),\n",
    "\n",
    "-- CTE: Block 4\n",
    "block_4 AS (\n",
    "    SELECT * FROM block_3 WHERE hospital IN ('AL', 'AK', 'AR')\n",
    "),\n",
    "\n",
    "-- CTE: Block 5\n",
    "block_5 AS (\n",
    "    SELECT * FROM orig_history WHERE hospital IN ('AL', 'AK', 'AR')\n",
    "),\n",
    "\n",
    "-- CTE: Block 6\n",
    "block_6 AS (\n",
    "    SELECT gave_consent, patient_rowid FROM orig_patient\n",
    "),\n",
    "\n",
    "-- CTE: Block 7\n",
    "block_7 AS (\n",
    "    SELECT * FROM block_6 WHERE gave_consent = TRUE\n",
    "),\n",
    "\n",
    "-- CTE: Block 8\n",
    "block_8 AS (\n",
    "    SELECT * FROM orig_patient WHERE gave_consent = TRUE\n",
    "),\n",
    "\n",
    "-- CTE: Block 9\n",
    "block_9 AS (\n",
    "    SELECT * FROM block_5 tb1 INNER JOIN block_8 tb2 ON tb1.ssn = tb2.ssn\n",
    "),\n",
    "\n",
    "-- CTE: Block 10\n",
    "block_10 AS (\n",
    "    SELECT gave_consent, patient_rowid FROM orig_patient\n",
    "),\n",
    "\n",
    "-- CTE: Block 11\n",
    "block_11 AS (\n",
    "    SELECT * FROM block_6 WHERE gave_consent = TRUE\n",
    "),\n",
    "\n",
    "-- CTE: Block 12\n",
    "block_12 AS (\n",
    "    SELECT * FROM orig_patient WHERE gave_consent = TRUE\n",
    "),\n",
    "\n",
    "-- CTE: Block 13\n",
    "block_13 AS (\n",
    "    SELECT * FROM block_12 tb1 INNER JOIN orig_test tb2 ON tb1.ssn = tb2.ssn\n",
    "),\n",
    "\n",
    "-- CTE: Block 14\n",
    "block_14 AS (\n",
    "    SELECT has_complication, history_rowid, patient_rowid FROM block_9\n",
    "),\n",
    "\n",
    "-- CTE: Block 15\n",
    "block_15 AS (\n",
    "    SELECT weight, history_rowid, patient_rowid FROM block_9\n",
    "),\n",
    "\n",
    "-- CTE: Block 16\n",
    "block_16 AS (\n",
    "    SELECT (weight - (SELECT AVG(weight) FROM block_9)) / (SELECT STDDEV_POP(weight) FROM block_9) AS weight, history_rowid, patient_rowid FROM block_9\n",
    "),\n",
    "\n",
    "-- CTE: Block 17\n",
    "block_17 AS (\n",
    "    SELECT smokes, history_rowid, patient_rowid FROM block_9\n",
    "),\n",
    "\n",
    "-- CTE: One Hot Encoding Helper\n",
    "one_hot_help AS (\n",
    "    SELECT\n",
    "        smokes,\n",
    "        list_resize(list_value(0), rank-1, 0) || [1] || list_resize(list_value(0), CAST((SELECT COUNT(DISTINCT smokes) FROM block_17) AS int)-rank, 0) AS one_hot\n",
    "    FROM (\n",
    "        SELECT smokes, CAST(ROW_NUMBER() OVER() AS int) AS rank\n",
    "        FROM (SELECT DISTINCT(smokes) FROM block_17) oh\n",
    "    ) one_hot_help\n",
    "),\n",
    "\n",
    "-- CTE: Block 18\n",
    "block_18 AS (\n",
    "    SELECT b9.history_rowid, b9.patient_rowid, o1.one_hot AS smokes FROM one_hot_help o1, block_9 b9 WHERE b9.smokes = o1.smokes\n",
    "),\n",
    "\n",
    "-- CTE: Block 19\n",
    "block_19 AS (\n",
    "    SELECT notes, history_rowid, patient_rowid FROM block_9\n",
    "),\n",
    "\n",
    "-- CTE: Block 21\n",
    "block_21 AS (\n",
    "    SELECT * FROM block_16 b16 INNER JOIN block_18 b18 ON b16.history_rowid = b18.history_rowid\n",
    "),\n",
    "\n",
    "-- CTE: Block 25\n",
    "block_25 AS (\n",
    "    SELECT weight, patient_rowid, test_rowid FROM block_13\n",
    "),\n",
    "\n",
    "-- CTE: Block 26\n",
    "block_26 AS (\n",
    "    SELECT (weight - (SELECT AVG(weight) FROM block_9)) / (SELECT STDDEV_POP(weight) FROM block_9) AS weight, patient_rowid, test_rowid FROM block_25\n",
    "),\n",
    "\n",
    "-- CTE: Block 27\n",
    "block_27 AS (\n",
    "    SELECT smokes, patient_rowid, test_rowid FROM block_13\n",
    "),\n",
    "\n",
    "-- CTE: One Hot Encoding Helper 2\n",
    "one_hot_help_2 AS (\n",
    "    SELECT\n",
    "        smokes,\n",
    "        list_resize(list_value(0), rank-1, 0) || [1] || list_resize(list_value(0), CAST((SELECT COUNT(DISTINCT smokes) FROM block_27) AS int)-rank, 0) AS one_hot\n",
    "    FROM (\n",
    "        SELECT smokes, CAST(ROW_NUMBER() OVER() AS int) AS rank\n",
    "        FROM (SELECT DISTINCT(smokes) FROM block_27) oh\n",
    "    ) one_hot_help\n",
    "),\n",
    "\n",
    "-- CTE: Block 28\n",
    "block_28 AS (\n",
    "    SELECT patient_rowid, test_rowid, o2.one_hot AS smokes FROM one_hot_help_2 o2, block_27 b27 WHERE b27.smokes = o2.smokes\n",
    "),\n",
    "\n",
    "-- CTE: Block 29\n",
    "block_29 AS (\n",
    "    SELECT notes, patient_rowid, test_rowid FROM block_13\n",
    "),\n",
    "\n",
    "-- CTE: Block 31\n",
    "block_31 AS (\n",
    "    SELECT * FROM block_26 b26 INNER JOIN block_28 b28 ON b26.patient_rowid = b28.patient_rowid\n",
    "),\n",
    "\n",
    "-- CTE: Block 34\n",
    "block_34 AS (\n",
    "    SELECT has_complication, patient_rowid, test_rowid FROM block_13\n",
    ")\n",
    "\n",
    "-- Main Query\n",
    "SELECT * FROM block_34;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "+-------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE VIEW orig_history AS\n",
    "SELECT rowid AS history_rowid, * FROM histories;\n",
    "\n",
    "CREATE VIEW orig_test AS\n",
    "SELECT rowid AS test_rowid, * FROM test_histories;\n",
    "\n",
    "CREATE VIEW orig_patient AS\n",
    "SELECT rowid AS patient_rowid, * FROM patients;\n",
    "\n",
    "CREATE VIEW block_3 AS\n",
    "SELECT hospital, history_rowid FROM orig_history;\n",
    "\n",
    "CREATE VIEW block_4 AS\n",
    "SELECT * FROM block_3 WHERE hospital IN ('AL', 'AK', 'AR');\n",
    "\n",
    "CREATE VIEW block_5 AS\n",
    "SELECT * FROM orig_history WHERE hospital IN ('AL', 'AK', 'AR');\n",
    "\n",
    "CREATE VIEW block_6 AS\n",
    "SELECT gave_consent, patient_rowid FROM orig_patient;\n",
    "\n",
    "CREATE VIEW block_7 AS\n",
    "SELECT * FROM block_6 WHERE gave_consent = TRUE;\n",
    "\n",
    "CREATE VIEW block_8 AS\n",
    "SELECT * FROM orig_patient WHERE gave_consent = TRUE;\n",
    "\n",
    "CREATE VIEW block_9 AS\n",
    "SELECT * FROM block_5 tb1 INNER JOIN block_8 tb2 ON tb1.ssn = tb2.ssn;\n",
    "\n",
    "CREATE VIEW block_10 AS\n",
    "SELECT gave_consent, patient_rowid FROM orig_patient;\n",
    "\n",
    "CREATE VIEW block_11 AS\n",
    "SELECT * FROM block_6 WHERE gave_consent = TRUE;\n",
    "\n",
    "CREATE VIEW block_12 AS\n",
    "SELECT * FROM orig_patient WHERE gave_consent = TRUE;\n",
    "\n",
    "CREATE VIEW block_13 AS\n",
    "SELECT * FROM block_12 tb1 INNER JOIN orig_test tb2 ON tb1.ssn = tb2.ssn;\n",
    "\n",
    "CREATE VIEW block_14 AS\n",
    "SELECT has_complication, history_rowid, patient_rowid FROM block_9;\n",
    "\n",
    "CREATE VIEW block_15 AS\n",
    "SELECT weight, history_rowid, patient_rowid FROM block_9;\n",
    "\n",
    "CREATE VIEW block_16 AS\n",
    "SELECT (weight - (SELECT AVG(weight) FROM block_9)) / (SELECT STDDEV_POP(weight) FROM block_9) AS weight, history_rowid, patient_rowid FROM block_9;\n",
    "\n",
    "CREATE VIEW block_17 AS\n",
    "SELECT smokes, history_rowid, patient_rowid FROM block_9;\n",
    "\n",
    "CREATE VIEW one_hot_help AS\n",
    "SELECT smokes, list_resize(list_value(0), rank-1, 0) || [1] || list_resize(list_value(0), CAST((SELECT COUNT(DISTINCT smokes) FROM block_17) AS int)-rank, 0) AS one_hot\n",
    "FROM(SELECT smokes, CAST(ROW_NUMBER() OVER() AS int) AS rank\n",
    "FROM (SELECT DISTINCT(smokes) FROM block_17) oh) one_hot_help;\n",
    "\n",
    "CREATE VIEW block_18 AS\n",
    "SELECT b9.history_rowid, b9.patient_rowid, o1.one_hot AS smokes FROM one_hot_help o1, block_9 b9 WHERE b9.smokes = o1.smokes;\n",
    "\n",
    "CREATE VIEW block_19 AS\n",
    "SELECT notes, history_rowid, patient_rowid FROM block_9;\n",
    "\n",
    "CREATE VIEW block_21 AS\n",
    "SELECT * FROM block_16 b16 INNER JOIN block_18 b18 ON b16.history_rowid = b18.history_rowid;\n",
    "\n",
    "CREATE VIEW block_25 AS\n",
    "SELECT weight, patient_rowid, test_rowid FROM block_13;\n",
    "\n",
    "CREATE VIEW block_26 AS\n",
    "SELECT (weight - (SELECT AVG(weight) FROM block_9)) / (SELECT STDDEV_POP(weight) FROM block_9) AS weight, patient_rowid, test_rowid FROM block_25;\n",
    "\n",
    "CREATE VIEW block_27 AS\n",
    "SELECT smokes, patient_rowid, test_rowid FROM block_13;\n",
    "\n",
    "CREATE VIEW one_hot_help_2 AS\n",
    "SELECT smokes, list_resize(list_value(0), rank-1, 0) || [1] || list_resize(list_value(0), CAST((SELECT COUNT(DISTINCT smokes) FROM block_27) AS int)-rank, 0) AS one_hot\n",
    "FROM(SELECT smokes, CAST(ROW_NUMBER() OVER() AS int) AS rank\n",
    "FROM (SELECT DISTINCT(smokes) FROM block_27) oh) one_hot_help;\n",
    "\n",
    "CREATE VIEW block_28 AS\n",
    "SELECT patient_rowid, test_rowid, o2.one_hot AS smokes FROM one_hot_help_2 o2, block_27 b27 WHERE b27.smokes = o2.smokes;\n",
    "\n",
    "CREATE VIEW block_29 AS\n",
    "SELECT notes, patient_rowid, test_rowid FROM block_13;\n",
    "\n",
    "CREATE VIEW block_31 AS\n",
    "SELECT * FROM block_26 b26 INNER JOIN block_28 b28 ON b26.patient_rowid = b28.patient_rowid;\n",
    "\n",
    "CREATE VIEW block_34 AS\n",
    "SELECT has_complication, patient_rowid, test_rowid FROM block_13;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code for comparison: `histories = histories[histories['hospital'].isin([\"AL\", \"AK\", \"AR\"])]`\n",
    "\n",
    "Corresponding files: `histories_pipeline.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>7577</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  7577 |\n",
       "+-------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT notes,has_complication,ssn,hospital FROM block_5;\n",
    "\n",
    "COPY (SELECT notes,has_complication,ssn,hospital FROM block_5 ORDER BY ssn) TO 'histories_duckdb.csv' WITH HEADER DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>has_complication</th>\n",
       "      <th>ssn</th>\n",
       "      <th>hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high risk</td>\n",
       "      <td>True</td>\n",
       "      <td>001-15-5323</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>True</td>\n",
       "      <td>001-24-5429</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>False</td>\n",
       "      <td>001-44-2119</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>False</td>\n",
       "      <td>001-63-3296</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>True</td>\n",
       "      <td>001-98-3642</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         notes  has_complication          ssn hospital\n",
       "0    high risk              True  001-15-5323       AL\n",
       "1  normal risk              True  001-24-5429       AR\n",
       "2  normal risk             False  001-44-2119       AK\n",
       "3  normal risk             False  001-63-3296       AR\n",
       "4  normal risk              True  001-98-3642       AL"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_path = \"histories_pipeline.csv\"\n",
    "histories_duckdb = pd.read_csv(file1_path, index_col=None)\n",
    "histories_duckdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notes</th>\n",
       "      <th>has_complication</th>\n",
       "      <th>ssn</th>\n",
       "      <th>hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high risk</td>\n",
       "      <td>True</td>\n",
       "      <td>001-15-5323</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>True</td>\n",
       "      <td>001-24-5429</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>False</td>\n",
       "      <td>001-44-2119</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>False</td>\n",
       "      <td>001-63-3296</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal risk</td>\n",
       "      <td>True</td>\n",
       "      <td>001-98-3642</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         notes  has_complication          ssn hospital\n",
       "0    high risk              True  001-15-5323       AL\n",
       "1  normal risk              True  001-24-5429       AR\n",
       "2  normal risk             False  001-44-2119       AK\n",
       "3  normal risk             False  001-63-3296       AR\n",
       "4  normal risk              True  001-98-3642       AL"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2_path = \"histories_duckdb.csv\"\n",
    "histories_duckdb = pd.read_csv(file2_path, index_col=None)\n",
    "histories_duckdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've written a function to check if the contents of two CSV files are identical. Since the order of data in the two CSV files might differ, the function takes a 'sort' parameter for sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_csv_files(file1, file2, sort):\n",
    "    \n",
    "    df1 = pd.read_csv(file1, index_col=None).sort_values(by=sort)\n",
    "    print(df1.head())\n",
    "    df2 = pd.read_csv(file2, index_col=None).sort_values(by=sort)\n",
    "    print(df2.head())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    if df1.values.tolist() == df2.values.tolist():\n",
    "        print(\"Files are identical.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Files are not identical.\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         notes  has_complication          ssn hospital\n",
      "0    high risk              True  001-15-5323       AL\n",
      "1  normal risk              True  001-24-5429       AR\n",
      "2  normal risk             False  001-44-2119       AK\n",
      "3  normal risk             False  001-63-3296       AR\n",
      "4  normal risk              True  001-98-3642       AL\n",
      "         notes  has_complication          ssn hospital\n",
      "0    high risk              True  001-15-5323       AL\n",
      "1  normal risk              True  001-24-5429       AR\n",
      "2  normal risk             False  001-44-2119       AK\n",
      "3  normal risk             False  001-63-3296       AR\n",
      "4  normal risk              True  001-98-3642       AL\n",
      "\n",
      "Files are identical.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_path = \"histories_pipeline.csv\"\n",
    "file2_path = \"histories_duckdb.csv\"\n",
    "\n",
    "compare_csv_files(file1_path, file2_path, 'ssn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code for comparison: `train = combine(patients, histories, consent_required=True)`\n",
    "\n",
    "Corresponding files: `train_pipeline_initial.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>7414</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  7414 |\n",
       "+-------+"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT smokes,weight,gave_consent,ssn,notes,has_complication,hospital FROM block_9;\n",
    "\n",
    "COPY (SELECT smokes,weight,gave_consent,ssn,notes,has_complication,hospital FROM block_9) TO 'train_duckdb_initial.csv' WITH HEADER DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  smokes     weight  gave_consent          ssn        notes  has_complication  \\\n",
      "0    yes  89.015953          True  001-15-5323    high risk              True   \n",
      "1     no  81.807574          True  001-24-5429  normal risk              True   \n",
      "2     no  60.288345          True  001-44-2119  normal risk             False   \n",
      "3     no  60.803919          True  001-63-3296  normal risk             False   \n",
      "4     no  79.317285          True  001-98-3642  normal risk              True   \n",
      "\n",
      "  hospital  \n",
      "0       AL  \n",
      "1       AR  \n",
      "2       AK  \n",
      "3       AR  \n",
      "4       AL  \n",
      "     smokes     weight  gave_consent          ssn        notes  \\\n",
      "3311    yes  89.015953          True  001-15-5323    high risk   \n",
      "2693     no  81.807574          True  001-24-5429  normal risk   \n",
      "3680     no  60.288345          True  001-44-2119  normal risk   \n",
      "5396     no  60.803919          True  001-63-3296  normal risk   \n",
      "114      no  79.317285          True  001-98-3642  normal risk   \n",
      "\n",
      "      has_complication hospital  \n",
      "3311              True       AL  \n",
      "2693              True       AR  \n",
      "3680             False       AK  \n",
      "5396             False       AR  \n",
      "114               True       AL  \n",
      "\n",
      "Files are identical.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_path = \"train_pipeline_initial.csv\"\n",
    "file2_path = \"train_duckdb_initial.csv\"\n",
    "\n",
    "compare_csv_files(file1_path, file2_path, 'ssn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code for comparison: `test = combine(patients, test_histories, consent_required=True)`\n",
    "\n",
    "Corresponding files: `test_pipeline_initial.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>3910</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  3910 |\n",
       "+-------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT smokes,weight,gave_consent,ssn,notes,has_complication,hospital FROM block_13;\n",
    "\n",
    "COPY (SELECT smokes,weight,gave_consent,ssn,notes,has_complication,hospital FROM block_13) TO 'test_duckdb_initial.csv' WITH HEADER DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  smokes     weight  gave_consent          ssn        notes  has_complication  \\\n",
      "0    yes  82.339362          True  001-50-6900  normal risk             False   \n",
      "1     no  81.674947          True  001-64-3715  normal risk             False   \n",
      "2     no   0.000000          True  001-91-5590  normal risk             False   \n",
      "3     no  64.290579          True  001-94-8928  normal risk              True   \n",
      "4    yes  82.575749          True  002-03-5384  normal risk             False   \n",
      "\n",
      "  hospital  \n",
      "0       AL  \n",
      "1       AR  \n",
      "2       AK  \n",
      "3       AZ  \n",
      "4       AR  \n",
      "     smokes     weight  gave_consent          ssn        notes  \\\n",
      "2690    yes  82.339362          True  001-50-6900  normal risk   \n",
      "3679     no  81.674947          True  001-64-3715  normal risk   \n",
      "1853     no   0.000000          True  001-91-5590  normal risk   \n",
      "347      no  64.290579          True  001-94-8928  normal risk   \n",
      "77      yes  82.575749          True  002-03-5384  normal risk   \n",
      "\n",
      "      has_complication hospital  \n",
      "2690             False       AL  \n",
      "3679             False       AR  \n",
      "1853             False       AK  \n",
      "347               True       AZ  \n",
      "77               False       AR  \n",
      "\n",
      "Files are identical.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_path = \"test_pipeline_initial.csv\"\n",
    "file2_path = \"test_duckdb_initial.csv\"\n",
    "\n",
    "compare_csv_files(file1_path, file2_path, 'ssn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code for comparison:\n",
    "\n",
    " `('numerical_features', StandardScaler(), ['weight'])`\n",
    "\n",
    "  `('categorical_features', OneHotEncoder(handle_unknown='ignore'), ['smokes'])`\n",
    "\n",
    "Corresponding files: `train_transformed.txt, test_transformed.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I converted two text files to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_txt_file = 'train_transformed.txt'\n",
    "output_csv_file = 'train_transformed.csv'\n",
    "\n",
    "with open(input_txt_file, 'r') as txt_file:\n",
    "    lines = txt_file.readlines()\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for line in lines:\n",
    "        fields = line.strip().split(' ')\n",
    "        csv_writer.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_txt_file = 'test_transformed.txt'\n",
    "output_csv_file = 'test_transformed.csv'\n",
    "\n",
    "with open(input_txt_file, 'r') as txt_file:\n",
    "    lines = txt_file.readlines()\n",
    "\n",
    "with open(output_csv_file, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for line in lines:\n",
    "        fields = line.strip().split(' ')\n",
    "        csv_writer.writerow(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>7414</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  7414 |\n",
       "+-------+"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT weight, smokes FROM block_21;\n",
    "\n",
    "COPY (SELECT weight, smokes FROM block_21) TO 'train_duckdb.csv' WITH HEADER DELIMITER ',';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data obtained from DuckDB and the pipeline to ensure consistent formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.085348</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.089705</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.741307</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.010239</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.919553</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     weight  smokes\n",
       "0  1.085348  [1, 0]\n",
       "1 -1.089705  [1, 0]\n",
       "2 -0.741307  [1, 0]\n",
       "3  1.010239  [0, 1]\n",
       "4 -0.919553  [1, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'train_duckdb.csv'\n",
    "df = pd.read_csv(file_path, index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>-1.903985</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5891</th>\n",
       "      <td>-1.858770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-1.852974</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6869</th>\n",
       "      <td>-1.814613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-1.776032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         col_0  col_1  col_2\n",
       "1361 -1.903985      1      0\n",
       "5891 -1.858770      1      0\n",
       "282  -1.852974      1      0\n",
       "6869 -1.814613      1      0\n",
       "165  -1.776032      0      1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'weight': 'col_0'}, inplace=True)\n",
    "df['smokes'] = df['smokes'].apply(eval)\n",
    "\n",
    "# Create separate columns for 'col_1' and 'col_2'\n",
    "df[['col_1', 'col_2']] = pd.DataFrame(df['smokes'].to_list(), columns=['col_1', 'col_2'])\n",
    "\n",
    "# Drop the original 'smokes' column\n",
    "df = df.drop('smokes', axis=1).sort_values(by=['col_0', 'col_1'])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_duckdb_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>-1.903985</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>-1.858770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>-1.852974</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>-1.814613</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>-1.776032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         col_0  col_1  col_2\n",
       "2226 -1.903985      1      0\n",
       "4890 -1.858770      1      0\n",
       "1304 -1.852974      1      0\n",
       "7392 -1.814613      1      0\n",
       "753  -1.776032      0      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'train_transformed.csv'\n",
    "df = pd.read_csv(file_path, index_col=None,header=None)\n",
    "df.columns = [f'col_{i}' for i in range(df.shape[1])]\n",
    "# convert the float numbers to int \n",
    "df[['col_1', 'col_2']] = df[['col_1', 'col_2']].astype(int)\n",
    "df = df.sort_values(by=['col_0', 'col_1'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_pipeline_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>3910</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  3910 |\n",
       "+-------+"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT weight, smokes FROM block_31;\n",
    "\n",
    "COPY (SELECT weight, smokes FROM block_31) TO 'test_duckdb.csv' WITH HEADER DELIMITER ',';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.713701</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5569.845352</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5569.845352</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636801</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5569.845352</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        weight  smokes\n",
       "0     0.713701  [1, 0]\n",
       "1  5569.845352  [0, 1]\n",
       "2  5569.845352  [0, 1]\n",
       "3     0.636801  [1, 0]\n",
       "4  5569.845352  [1, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'test_duckdb.csv'\n",
    "df = pd.read_csv(file_path, index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3910.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.102419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2219.069214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.511366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.075109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.264598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.389069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5569.845352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            weight\n",
       "count  3910.000000\n",
       "mean   1100.102419\n",
       "std    2219.069214\n",
       "min      -6.511366\n",
       "25%      -1.075109\n",
       "50%       0.264598\n",
       "75%       1.389069\n",
       "max    5569.845352"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        col_0  col_1  col_2\n",
       "28  -6.511366      0      1\n",
       "31  -6.511366      0      1\n",
       "47  -6.511366      0      1\n",
       "97  -6.511366      0      1\n",
       "116 -6.511366      0      1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'weight': 'col_0'}, inplace=True)\n",
    "df['smokes'] = df['smokes'].apply(eval)\n",
    "\n",
    "# Create separate columns for 'col_1' and 'col_2'\n",
    "df[['col_1', 'col_2']] = pd.DataFrame(df['smokes'].to_list(), columns=['col_1', 'col_2'])\n",
    "\n",
    "# Drop the original 'smokes' column\n",
    "df = df.drop('smokes', axis=1)\n",
    "df = df.sort_values(by=['col_0', 'col_1'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_duckdb_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-6.511366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       col_0  col_1  col_2\n",
       "42 -6.511366      0      1\n",
       "50 -6.511366      0      1\n",
       "53 -6.511366      0      1\n",
       "56 -6.511366      0      1\n",
       "83 -6.511366      0      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'test_transformed.csv'\n",
    "df = pd.read_csv(file_path, index_col=None, header=None)\n",
    "df.columns = [f'col_{i}' for i in range(df.shape[1])]\n",
    "# convert the float numbers to int \n",
    "df[['col_1', 'col_2']] = df[['col_1', 'col_2']].astype(int)\n",
    "df = df.sort_values(by=['col_0', 'col_1'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_pipeline_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the potential variability in precision across different systems, we establish a tolerance to facilitate the comparison of floating-point data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compare_csv_with_tolerance(file1, file2, tolerance=1e-6):\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    if df1.shape != df2.shape:\n",
    "        print(\"CSV files have different shapes.\")\n",
    "        return\n",
    "\n",
    "    differences = []\n",
    "\n",
    "    for row in range(df1.shape[0]):\n",
    "        for col in df1.columns:\n",
    "            val1 = df1.at[row, col]\n",
    "            val2 = df2.at[row, col]\n",
    "\n",
    "            if not np.isclose(val1, val2, rtol=tolerance, atol=tolerance):\n",
    "                differences.append((row, col))\n",
    "\n",
    "    if differences:\n",
    "        print(\"CSV files are not equal. Differences found at:\")\n",
    "        for diff in differences:\n",
    "            print(f\"Row: {diff[0]}, Column: {diff[1]}\")\n",
    "    else:\n",
    "        print(\"CSV files are equal.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files are equal.\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "file1_path = \"train_pipeline_final.csv\"\n",
    "file2_path = \"train_duckdb_final.csv\"\n",
    "\n",
    "compare_csv_with_tolerance(file1_path, file2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files are equal.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "file3_path = \"test_pipeline_final.csv\"\n",
    "file4_path = \"test_duckdb_final.csv\"\n",
    "\n",
    "compare_csv_with_tolerance(file3_path, file4_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All checks have been completed at this point, and the data obtained after DuckDB operations matches the data generated by the Python pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
